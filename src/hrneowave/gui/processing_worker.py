#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ProcessingWorker - Worker pour le traitement temps r√©el des donn√©es d'acquisition

Ce module impl√©mente un worker QThread pour le traitement en temps r√©el
des donn√©es d'acquisition avec FFT et analyse spectrale.
"""

import time
import numpy as np
from PyQt5.QtCore import QThread, pyqtSignal, QTimer, QMutex, QMutexLocker
from typing import Dict, Any, Optional, List, Tuple

try:
    from hrneowave.core.circular_buffer import create_circular_buffer, BufferConfig
    CircularBuffer = create_circular_buffer
except ImportError:
    CircularBuffer = None
    BufferConfig = None
    print("‚ö†Ô∏è CircularBuffer non disponible")


class LatencyMonitor:
    """Moniteur de latence pour le traitement temps r√©el"""
    
    def __init__(self):
        self.start_times = {}
        self.latencies = []
        self.max_latency = 0.0
        self.avg_latency = 0.0
    
    def start_measurement(self, measurement_id: str):
        """D√©marre une mesure de latence"""
        self.start_times[measurement_id] = time.perf_counter()
    
    def end_measurement(self, measurement_id: str) -> float:
        """Termine une mesure de latence et retourne la dur√©e"""
        if measurement_id in self.start_times:
            latency = time.perf_counter() - self.start_times[measurement_id]
            self.latencies.append(latency)
            
            # Garder seulement les 100 derni√®res mesures
            if len(self.latencies) > 100:
                self.latencies = self.latencies[-100:]
            
            self.max_latency = max(self.latencies)
            self.avg_latency = np.mean(self.latencies)
            
            del self.start_times[measurement_id]
            return latency
        return 0.0
    
    def get_stats(self) -> Dict[str, float]:
        """Retourne les statistiques de latence"""
        return {
            'max_latency': self.max_latency,
            'avg_latency': self.avg_latency,
            'current_measurements': len(self.start_times)
        }


class ProcessingWorker(QThread):
    """
    Worker pour le traitement temps r√©el des donn√©es d'acquisition.
    
    Signaux √©mis:
    - newSpectra: Nouveaux spectres calcul√©s
    - newStats: Nouvelles statistiques
    - performanceStats: M√©triques de performance
    - processingError: Erreurs de traitement
    """
    
    # Signaux PyQt
    newSpectra = pyqtSignal(dict)
    newStats = pyqtSignal(dict)
    performanceStats = pyqtSignal(dict)
    processingError = pyqtSignal(str)
    
    def __init__(self, parent, config: Dict[str, Any]):
        """
        Initialise le worker.
        
        Args:
            parent: Widget parent (g√©n√©ralement AcquisitionController)
            config: Configuration du traitement
        """
        super().__init__(parent)
        
        self.parent = parent
        self.config = config
        self.running = False
        self.mutex = QMutex()
        
        # Configuration par d√©faut
        self.sampling_rate = config.get('sample_rate', 1000.0)
        self.window_size = config.get('window_size', 1024)
        self.overlap = config.get('overlap', 0.5)
        self.update_interval = config.get('update_interval', 2.0)
        self.n_channels = config.get('n_channels', 4)
        
        # Initialiser les buffers
        self._init_buffers()
        
        # Timer pour le traitement p√©riodique
        self.process_timer = QTimer()
        self.process_timer.timeout.connect(self.process_data)
        
        # Moniteur de latence
        self.latency_monitor = LatencyMonitor()
        
        # M√©triques de performance
        self.performance_metrics = {
            'fft_time': 0.0,
            'processing_time': 0.0,
            'total_time': 0.0,
            'throughput': 0.0,
            'processed_samples': 0
        }
        
        print("‚úÖ ProcessingWorker initialis√©")
    
    def _init_buffers(self):
        """Initialise les buffers circulaires"""
        try:
            buffer_size = int(self.sampling_rate * 10)  # 10 secondes de donn√©es
            
            if CircularBuffer and BufferConfig:
                # Buffer pour le temps (1 canal)
                time_config = BufferConfig(
                    n_channels=1,
                    buffer_size=buffer_size,
                    sample_rate=self.sampling_rate
                )
                self.time_buffer = CircularBuffer(time_config)
                
                # Buffers pour les donn√©es (1 canal chacun)
                self.data_buffers = []
                for i in range(self.n_channels):
                    data_config = BufferConfig(
                        n_channels=1,
                        buffer_size=buffer_size,
                        sample_rate=self.sampling_rate
                    )
                    self.data_buffers.append(CircularBuffer(data_config))
            else:
                # Fallback vers des listes Python
                self.time_buffer = []
                self.data_buffers = [[] for _ in range(self.n_channels)]
                
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur initialisation buffers: {e}")
            self.time_buffer = []
            self.data_buffers = [[] for _ in range(self.n_channels)]
    
    def start_processing(self):
        """D√©marre le traitement en arri√®re-plan"""
        with QMutexLocker(self.mutex):
            if not self.running:
                self.running = True
                self.start()
                
                # D√©marrer le timer de traitement
                interval_ms = int(self.update_interval * 1000)
                self.process_timer.start(interval_ms)
                
                print("üöÄ ProcessingWorker d√©marr√©")
    
    def stop_processing(self):
        """Arr√™te le traitement"""
        with QMutexLocker(self.mutex):
            if self.running:
                self.running = False
                self.process_timer.stop()
                self.quit()
                self.wait(5000)  # Attendre max 5 secondes
                
                print("‚èπÔ∏è ProcessingWorker arr√™t√©")
    
    def run(self):
        """Boucle principale du thread"""
        print("üîÑ ProcessingWorker en cours d'ex√©cution")
        
        while self.running:
            try:
                # R√©cup√©rer les nouvelles donn√©es
                self._collect_data()
                
                # Attendre un peu avant la prochaine collecte
                self.msleep(100)  # 100ms
                
            except Exception as e:
                self.processingError.emit(f"Erreur dans la boucle principale: {e}")
                break
    
    def _collect_data(self):
        """Collecte les donn√©es depuis le parent"""
        try:
            if hasattr(self.parent, 'get_latest_data'):
                data = self.parent.get_latest_data()
                if data is not None:
                    self._add_data_to_buffers(data)
                    
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur collecte donn√©es: {e}")
    
    def _add_data_to_buffers(self, data):
        """Ajoute les donn√©es aux buffers"""
        try:
            if isinstance(data, dict) and 'time' in data and 'channels' in data:
                time_data = data['time']
                channel_data = data['channels']
                
                # Ajouter aux buffers
                if isinstance(self.time_buffer, list):
                    self.time_buffer.extend(time_data)
                    for i, channel in enumerate(channel_data):
                        if i < len(self.data_buffers):
                            self.data_buffers[i].extend(channel)
                else:
                    # CircularBuffer
                    import numpy as np
                    if time_data:
                        time_array = np.array(time_data).reshape(-1, 1)  # Reshape pour 1 canal
                        self.time_buffer.write(time_array)
                    
                    for i, channel in enumerate(channel_data):
                        if i < len(self.data_buffers) and channel:
                            channel_array = np.array(channel).reshape(-1, 1)  # Reshape pour 1 canal
                            self.data_buffers[i].write(channel_array)
                                
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur ajout donn√©es aux buffers: {e}")
    
    def process_data(self):
        """Traite les donn√©es disponibles"""
        try:
            self.latency_monitor.start_measurement('processing')
            
            # R√©cup√©rer les donn√©es des buffers
            if self._has_sufficient_data():
                data = self._get_processing_data()
                
                if data is not None:
                    # Calculer FFT
                    spectra = self._compute_fft(data)
                    
                    # Calculer statistiques
                    stats = self._compute_stats(data)
                    
                    # √âmettre les r√©sultats
                    if spectra:
                        self.newSpectra.emit(spectra)
                    
                    if stats:
                        self.newStats.emit(stats)
                    
                    # M√©triques de performance
                    processing_time = self.latency_monitor.end_measurement('processing')
                    self.performance_metrics['processing_time'] = processing_time
                    self.performance_metrics['processed_samples'] += len(data.get('time', []))
                    
                    self.performanceStats.emit(self.performance_metrics.copy())
                    
        except Exception as e:
            self.processingError.emit(f"Erreur traitement: {e}")
    
    def _has_sufficient_data(self) -> bool:
        """V√©rifie s'il y a suffisamment de donn√©es pour traiter"""
        try:
            if isinstance(self.time_buffer, list):
                return len(self.time_buffer) >= self.window_size
            else:
                return self.time_buffer.available_samples() >= self.window_size
        except:
            return False
    
    def _get_processing_data(self) -> Optional[Dict]:
        """R√©cup√®re les donn√©es pour le traitement"""
        try:
            if isinstance(self.time_buffer, list):
                # Prendre les derni√®res donn√©es
                time_data = self.time_buffer[-self.window_size:]
                channel_data = []
                for buffer in self.data_buffers:
                    if len(buffer) >= self.window_size:
                        channel_data.append(buffer[-self.window_size:])
                    else:
                        channel_data.append([])
            else:
                # CircularBuffer
                time_buffer_data = self.time_buffer.get_data(self.window_size)
                time_data = time_buffer_data.flatten().tolist() if time_buffer_data is not None else []
                
                channel_data = []
                for buffer in self.data_buffers:
                    buffer_data = buffer.get_data(self.window_size)
                    if buffer_data is not None:
                        channel_data.append(buffer_data.flatten().tolist())
                    else:
                        channel_data.append([])
            
            return {
                'time': time_data,
                'channels': channel_data
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur r√©cup√©ration donn√©es: {e}")
            return None
    
    def _compute_fft(self, data: Dict) -> Optional[Dict]:
        """Calcule la FFT des donn√©es"""
        try:
            self.latency_monitor.start_measurement('fft')
            
            spectra = {}
            time_data = np.array(data['time'])
            
            if len(time_data) < 2:
                return None
            
            # Calculer la fr√©quence d'√©chantillonnage
            dt = np.mean(np.diff(time_data))
            fs = 1.0 / dt if dt > 0 else self.sampling_rate
            
            for i, channel_data in enumerate(data['channels']):
                if len(channel_data) >= self.window_size:
                    # Appliquer une fen√™tre
                    windowed_data = np.array(channel_data) * np.hanning(len(channel_data))
                    
                    # Calculer FFT
                    fft_result = np.fft.fft(windowed_data)
                    freqs = np.fft.fftfreq(len(windowed_data), 1/fs)
                    
                    # Prendre seulement les fr√©quences positives
                    positive_freqs = freqs[:len(freqs)//2]
                    positive_fft = np.abs(fft_result[:len(fft_result)//2])
                    
                    spectra[f'channel_{i}'] = {
                        'frequencies': positive_freqs.tolist(),
                        'amplitudes': positive_fft.tolist()
                    }
            
            fft_time = self.latency_monitor.end_measurement('fft')
            self.performance_metrics['fft_time'] = fft_time
            
            return spectra
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur calcul FFT: {e}")
            return None
    
    def _compute_stats(self, data: Dict) -> Optional[Dict]:
        """Calcule les statistiques des donn√©es"""
        try:
            stats = {}
            
            for i, channel_data in enumerate(data['channels']):
                if len(channel_data) > 0:
                    channel_array = np.array(channel_data)
                    
                    stats[f'channel_{i}'] = {
                        'mean': float(np.mean(channel_array)),
                        'std': float(np.std(channel_array)),
                        'min': float(np.min(channel_array)),
                        'max': float(np.max(channel_array)),
                        'rms': float(np.sqrt(np.mean(channel_array**2)))
                    }
            
            return stats
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur calcul statistiques: {e}")
            return None
    
    def add_data(self, time_data, channel_data):
        """Ajoute des donn√©es au worker (interface publique)"""
        data = {
            'time': time_data if isinstance(time_data, list) else [time_data],
            'channels': channel_data if isinstance(channel_data[0], list) else [channel_data]
        }
        self._add_data_to_buffers(data)
    
    def get_latency_stats(self) -> Dict[str, float]:
        """Retourne les statistiques de latence"""
        return self.latency_monitor.get_stats()